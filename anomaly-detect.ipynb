{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Malware in TLS with Machine Learning\r\n",
    "- Presented by Bryan Scarbrough\r\n",
    "- GSEC, GCIH, GCIA, GPYC, GXPN, GNFA, GCCC\r\n",
    "- Masterâ€™s Degree Candidate at the SANS Technology Institute\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\r\n",
    "\r\n",
    "### Import Modules and Data\r\n",
    "\r\n",
    "- First stage of analysis is to import the required modules\r\n",
    "- Create a function to import the data for processing\r\n",
    "- Then print the dataset to verify successful import\r\n",
    "\r\n",
    "---\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        dom_in_tranco_1m  dom_dga_prob  otx_status  otx_age  urlhaus_status  \\\n",
      "0               0.000000      0.000219           1    906.0             0.0   \n",
      "1               0.000000      0.000465           0      0.0             0.0   \n",
      "2               0.933333      0.001369           1    445.0             0.0   \n",
      "3               0.000000      0.000555           1    924.0             0.0   \n",
      "4               0.000000      0.001344           1    345.0             0.0   \n",
      "...                  ...           ...         ...      ...             ...   \n",
      "116907          0.000000      0.000808           0      0.0             0.0   \n",
      "116908          0.000000      0.000218           0      0.0             0.0   \n",
      "116909          0.000000      0.001534           0      0.0             0.0   \n",
      "116910          0.000000      0.000255           1    913.0             0.0   \n",
      "116911          0.000000      0.001290           0      0.0             0.0   \n",
      "\n",
      "        urlhaus_age  ja3_urlhaus_status  ja3_urlhaus_age  tls_record_type  \\\n",
      "0               0.0                 0.0              0.0             22.0   \n",
      "1               0.0                 0.0              0.0             22.0   \n",
      "2               0.0                 0.0              0.0             22.0   \n",
      "3               0.0                 0.0              0.0             22.0   \n",
      "4               0.0                 0.0              0.0             22.0   \n",
      "...             ...                 ...              ...              ...   \n",
      "116907          0.0                 0.0              0.0             22.0   \n",
      "116908          0.0                 0.0              0.0             22.0   \n",
      "116909          0.0                 0.0              0.0             22.0   \n",
      "116910          0.0                 0.0              0.0             22.0   \n",
      "116911          0.0                 0.0              0.0             22.0   \n",
      "\n",
      "        client_tls_ver  ...  svr_ext_52  svr_ext_53  svr_ext_55  svr_ext_56  \\\n",
      "0                769.0  ...         0.0         0.0         0.0         0.0   \n",
      "1                769.0  ...         0.0         0.0         0.0         0.0   \n",
      "2                769.0  ...         0.0         0.0         0.0         0.0   \n",
      "3                769.0  ...         0.0         0.0         0.0         0.0   \n",
      "4                769.0  ...         0.0         0.0         0.0         0.0   \n",
      "...                ...  ...         ...         ...         ...         ...   \n",
      "116907           771.0  ...         0.0         0.0         0.0         0.0   \n",
      "116908           769.0  ...         0.0         0.0         0.0         0.0   \n",
      "116909           769.0  ...         0.0         0.0         0.0         0.0   \n",
      "116910           769.0  ...         0.0         0.0         0.0         0.0   \n",
      "116911           771.0  ...         0.0         0.0         0.0         0.0   \n",
      "\n",
      "        svr_ext_65281  svr_ext_unassigned  svr_ocsp_staple  svr_tls_ver  \\\n",
      "0                 0.5                 0.0              1.0        771.0   \n",
      "1                 0.5                 0.0              0.0        771.0   \n",
      "2                 0.5                 0.0              0.0        771.0   \n",
      "3                 0.5                 0.0              1.0        771.0   \n",
      "4                 0.0                 0.0              0.0        771.0   \n",
      "...               ...                 ...              ...          ...   \n",
      "116907            0.5                 0.0              1.0        771.0   \n",
      "116908            0.5                 0.0              1.0        771.0   \n",
      "116909            0.5                 0.0              0.0        771.0   \n",
      "116910            0.5                 0.0              0.0        771.0   \n",
      "116911            0.5                 0.0              0.0        771.0   \n",
      "\n",
      "        svr_supported_ver  malware_label  \n",
      "0                     0.0            1.0  \n",
      "1                     0.0            1.0  \n",
      "2                     0.0            1.0  \n",
      "3                     0.0            1.0  \n",
      "4                   772.0            1.0  \n",
      "...                   ...            ...  \n",
      "116907                0.0           -1.0  \n",
      "116908                0.0            1.0  \n",
      "116909                0.0            1.0  \n",
      "116910                0.0            1.0  \n",
      "116911                0.0           -1.0  \n",
      "\n",
      "[116912 rows x 519 columns]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Import some initial libraries to get started\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Set a random state variable for selection consistency\n",
    "rand_state = 42\n",
    "\n",
    "# Set malware label\n",
    "label = 'malware_label'\n",
    "\n",
    "# Function to import and format the dataset for processing\n",
    "def get_data(sample_size, mal_percent=20, scaled=False):\n",
    "    csv_data_file = r'./data/test_train_data.csv'\n",
    "    full_dataset = pd.read_csv(csv_data_file)\n",
    "\n",
    "    # Scale data to 0-1 value for more efficient ML analysis\n",
    "    if scaled:\n",
    "        mm_data = MinMaxScaler().fit_transform(full_dataset)\n",
    "        full_dataset = pd.DataFrame(mm_data, columns=full_dataset.columns)\n",
    "\n",
    "    # Convert label values to 1 and -1 (this is how OC-SVM performs predictions\n",
    "    # so validation requires these values\n",
    "    ben = 1\n",
    "    mal = -1\n",
    "    full_dataset.loc[full_dataset[label] == 1, label] = mal\n",
    "    full_dataset.loc[full_dataset[label] == 0, label] = ben\n",
    "\n",
    "    # Split dataset into benign and malware\n",
    "    benign = full_dataset[full_dataset.malware_label == ben]\n",
    "    malware = full_dataset[full_dataset.malware_label == mal]\n",
    "    \n",
    "    # Determine malware percentage of sample dataset size\n",
    "    mal_size = int((mal_percent / 100) * sample_size)\n",
    "\n",
    "    # Prevent malware sample size from being larger than actual sample size\n",
    "    if mal_size > malware.shape[0]:\n",
    "        mal_size = malware.shape[0]\n",
    "\n",
    "    # Generate random sample of malware of size determined by mal_size variable\n",
    "    malware = malware.sample(n=mal_size, random_state=rand_state)\n",
    "\n",
    "    # Prevent total sample size from being larger than actual sample size\n",
    "    total_sample_size = sample_size - mal_size\n",
    "    if total_sample_size > benign.shape[0]:\n",
    "        total_sample_size = benign.shape[0]\n",
    "\n",
    "    # Now generate a benign data sample and combine the benign and malware samples\n",
    "    # to a single returned dataset\n",
    "    benign = benign.sample(n=total_sample_size, random_state=rand_state)\n",
    "    sampled_data = benign.append(malware).reset_index(drop=True)\n",
    "    sampled_data = sampled_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # Return sample dataset\n",
    "    return sampled_data\n",
    "\n",
    "# Generate initial full dataset for analysis\n",
    "full_dataset = get_data(117000)\n",
    "\n",
    "# Drop rows with NaN (improperly calculated values rendered as Not-a-Number)\n",
    "full_dataset = full_dataset.dropna()\n",
    "\n",
    "# Print a sample of the 5K dataset\n",
    "print(full_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\r\n",
    "\r\n",
    "## Data Analysis\r\n",
    "\r\n",
    "Before conducting any ML processing it is:\r\n",
    "\r\n",
    "  - Necessary to understand the nature of the data's relationships\r\n",
    "  - Determine the significance of various data features and how they are related to one another\r\n",
    "\r\n",
    "### Data Distribution\r\n",
    "\r\n",
    "Below is the percent distribution of Malware to Benign data.\r\n",
    "\r\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column to analyze\n",
    "target = full_dataset[label]\n",
    "# Get dataset length for percentage calculation\n",
    "total = len(full_dataset)\n",
    "# Define graph area and title\n",
    "plt.figure(figsize = (6, 6))\n",
    "plt.title(\"Malware Dataset Distribution\")\n",
    "\n",
    "# Generate count plot and turn into bar graph for display\n",
    "ax = sns.countplot(target)\n",
    "for p in ax.patches:\n",
    "    percentage = '{:.0f}%'.format(p.get_height() / total * 100)\n",
    "    x = p.get_x() + p.get_width() / 2\n",
    "    y = p.get_height() + 5\n",
    "    ax.annotate(percentage, (x, y), ha = 'center')\n",
    "    ax.set_xticklabels(['Benign', 'Malware'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\r\n",
    "\r\n",
    "## Cipher Suite Analysis\r\n",
    "\r\n",
    "- Time to analyze some of the individual features\r\n",
    "- Begin with Cipher Suties (the metadata value with the largest number of features)\r\n",
    "- The first graph shows the number of unique cipher suites used by each data classification (benign and malware)\r\n",
    "- The bottom graphs represent the most used cipher suites sorted by classification\r\n",
    "  - Left: Benign Cipher Suties used\r\n",
    "  - Right: Malicious Cipher Suites used\r\n",
    "\r\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate dataset by malware label\n",
    "mal = full_dataset[full_dataset.malware_label == -1]\n",
    "ben = full_dataset[full_dataset.malware_label == 1]\n",
    "\n",
    "# Select only Cipher Suite columns\n",
    "mal_cs_data = mal.filter(regex='cs_')\n",
    "ben_cs_data = ben.filter(regex='cs_')\n",
    "\n",
    "# Average Cipher Suite length value to graph in next cell\n",
    "mal_cs_size = round(mal_cs_data['cs_len'].sum() / len(mal_cs_data['cs_len']), 2)\n",
    "ben_cs_size = round(ben_cs_data['cs_len'].sum() / len(ben_cs_data['cs_len']), 2)\n",
    "\n",
    "# Drop Cipher Suite length field - not related to number of CS values offered by client\n",
    "mal_cs_data = mal_cs_data.drop(['cs_len'], axis=1)\n",
    "ben_cs_data = ben_cs_data.drop(['cs_len'], axis=1)\n",
    "\n",
    "# Drop columns containing only \"0\" values - these are CS values never offered by clients\n",
    "# Then determine the length of remaining values to determine number of CS values\n",
    "mal_cs_count = len(mal_cs_data.loc[:, (mal_cs_data != 0).any(axis=0)].columns)\n",
    "ben_cs_count = len(ben_cs_data.loc[:, (ben_cs_data != 0).any(axis=0)].columns)\n",
    "\n",
    "# Create graph container\n",
    "fig, axes = plt.subplots(2, 2, sharex=False, figsize=(15,12))\n",
    "\n",
    "# Calculate total number unique of Benign and Malware Cipher Suites used\n",
    "cs_count = pd.DataFrame({'Unique Cipher Suites': ['Benign Cipher Suites', 'Malware Cipher Suites'], 'Count': [ben_cs_count, mal_cs_count]})\n",
    "ax = sns.barplot(ax=axes[0,0], data=cs_count, y='Count', x='Unique Cipher Suites')\n",
    "for bar in ax.patches:\n",
    "    ax.annotate(format(bar.get_height(), ''),\n",
    "                    (bar.get_x() + bar.get_width() / 2,  \n",
    "                    bar.get_height()), ha='center', va='center', \n",
    "                    size=15, xytext=(0, 8), \n",
    "                    textcoords='offset points')\n",
    "\n",
    "# Sort cipher suites used by Benign importance\n",
    "ben_cs_sum = pd.DataFrame({\"Benign\": (ben_cs_data.sum() / len(ben_cs_data)), \"Malware\": (mal_cs_data.sum() / len(mal_cs_data))}, index=ben_cs_data.sum().sort_values().index).tail(20)\n",
    "ben_cs_sum.plot.barh(ax=axes[1,0], rot=0)\n",
    "axes[1,0].set_xlabel('Cipher Suites by Benign Importance')\n",
    "\n",
    "# Sorce cipher suites used by Malware importance\n",
    "mal_cs_sum = pd.DataFrame({\"Benign\": (ben_cs_data.sum() / len(ben_cs_data)), \"Malware\": (mal_cs_data.sum() / len(mal_cs_data))}, index=mal_cs_data.sum().sort_values().index).tail(20)\n",
    "mal_cs_sum.plot.barh(ax=axes[1,1], rot=0)\n",
    "axes[1,1].set_xlabel('Cipher Suites by Malware Importance')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\r\n",
    "\r\n",
    "## Port Analysis\r\n",
    "\r\n",
    "- The next section of features worthy of analysis are the ports used\r\n",
    "\r\n",
    "> NOTE: While these values are easily changeable by an attacker, they can easily be overlooked, and for the purposes of this research offer a significant statistical variation leading to successful ML analysis.\r\n",
    "\r\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PORT ANALYSIS\n",
    "#\n",
    "# Create dataframe of malicious and benign source and destination ports\n",
    "mal_prt = mal[['src_port', 'dst_port']]\n",
    "ben_prt = ben[['src_port', 'dst_port']]\n",
    "\n",
    "# Create graph container\n",
    "fig, axes = plt.subplots(3, 2, sharex=False, figsize=(15,15))\n",
    "\n",
    "# Calculate and graph number of unique destination ports\n",
    "ben_dst_percent = ben_prt.dst_port.unique().shape[0]\n",
    "mal_dst_percent = mal_prt.dst_port.unique().shape[0]\n",
    "dst_prt_sum = pd.DataFrame({'Unique Destination Ports': ['Benign Unique Dst Ports', 'Malware Unique Dst Ports'], 'Count': [ ben_dst_percent, mal_dst_percent]})\n",
    "ax = sns.barplot(ax=axes[0,0], data=dst_prt_sum, y='Count', x='Unique Destination Ports')\n",
    "for bar in ax.patches:\n",
    "    ax.annotate(format(bar.get_height(), ''),\n",
    "                    (bar.get_x() + bar.get_width() / 2,  \n",
    "                    bar.get_height()), ha='center', va='center', \n",
    "                    size=15, xytext=(0, 8), \n",
    "                    textcoords='offset points')\n",
    "\n",
    "# Calculate and graph number of unique source ports\n",
    "ben_src_percent = (ben_prt.src_port.unique().shape[0] / len(ben_prt.src_port)) * 100\n",
    "mal_src_percent = (mal_prt.src_port.unique().shape[0] / len(mal_prt.src_port)) * 100\n",
    "src_prt_sum = pd.DataFrame({'Unique Source Ports': ['Benign Unique Src Ports', 'Malware Unique Src Ports'], 'Count': [ ben_src_percent, mal_src_percent]})\n",
    "ax = sns.barplot(ax=axes[0,1], data=src_prt_sum, y='Count', x='Unique Source Ports')\n",
    "for bar in ax.patches:\n",
    "    ax.annotate('{:.2f}%'.format(bar.get_height(), ''),\n",
    "                    (bar.get_x() + bar.get_width() / 2,  \n",
    "                    bar.get_height()), ha='center', va='center', \n",
    "                    size=15, xytext=(0, 8), \n",
    "                    textcoords='offset points')\n",
    "\n",
    "# Determine top benign destination ports\n",
    "ben_dst_prt = pd.DataFrame(ben_prt.dst_port.astype(int).value_counts().sort_values())\n",
    "ax = sns.barplot(ax=axes[1,0], data=cs_count, y=ben_dst_prt.dst_port, x=ben_dst_prt.index, orient='v')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "ax.set(xlabel='Benign Destionation Ports', ylabel='Count')\n",
    "\n",
    "# Determine top malware destination ports\n",
    "mal_dst_prt = pd.DataFrame(mal_prt.dst_port.astype(int).value_counts().sort_values()).tail(10)\n",
    "ax = sns.barplot(ax=axes[1,1], data=cs_count, y=mal_dst_prt.dst_port, x=mal_dst_prt.index, orient='v')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "ax.set(xlabel='Malware Destination Ports', ylabel='Count')\n",
    "\n",
    "# Determine top benign source ports\n",
    "ben_src_prt = pd.DataFrame(ben_prt.src_port.astype(int).value_counts()).head(10)\n",
    "ax = sns.barplot(ax=axes[2,0], data=cs_count, y=ben_src_prt.src_port, x=ben_src_prt.index, orient='v')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "ax.set(xlabel='Benign Source Ports', ylabel='Count')\n",
    "\n",
    "# Determine top malware sourceports\n",
    "mal_src_prt = pd.DataFrame(mal_prt.src_port.astype(int).value_counts()).head(10)\n",
    "ax = sns.barplot(ax=axes[2,1], data=cs_count, y=mal_src_prt.src_port, x=mal_src_prt.index, orient='v')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "ax.set(xlabel='Malware Source Ports', ylabel='Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\r\n",
    "\r\n",
    "### How a Support Vector Machine (SVM) Works...\r\n",
    "\r\n",
    "- Binary classification system\r\n",
    "- Calculates best line (or plane, also called hyperplane) to separate data\r\n",
    "- Measures distance between nearest samples to hyperplane\r\n",
    "  - Measurement determines the margin\r\n",
    "  - Nearest samples called the Support Vectors\r\n",
    "- When data is non-linear (cannot separate with straight line), SVM uses \"kernels\" to classify\r\n",
    "\r\n",
    "![SVM Margin](./images/svm-margin.jpg)\r\n",
    "\r\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "test_percent = 20\n",
    "\n",
    "formatted_data = get_data(50000, 125, True)\n",
    "\n",
    "label_data = formatted_data.malware_label\n",
    "feature_data = formatted_data.drop(label, axis=1)\n",
    "\n",
    "pca = PCA(n_components=2).fit_transform(feature_data)\n",
    "data = pd.DataFrame(pca)\n",
    "\n",
    "svm_x_train, svm_x_test, svm_y_train, svm_x_test = train_test_split(data, label_data, test_size=(test_percent / 100), random_state=rand_state)\n",
    "\n",
    "svclassifier = SVC(kernel='rbf', C=1, gamma=0.1, probability=True, random_state=42)\n",
    "svclassifier.fit(svm_x_train, svm_y_train)\n",
    "x_data = np.array(data)\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.scatter(x_data[:, 0], x_data[:, 1], c=label_data.values, s=40, cmap=plt.cm.winter, alpha=0.5)\n",
    "ax = plt.gca()\n",
    "xlim = [-2, 2]\n",
    "ylim = [-5, 4]\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "XX, YY = np.meshgrid(xx, yy)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = svclassifier.decision_function(xy).reshape(XX.shape)\n",
    "\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5, linestyles=['--', '-', '--'])\n",
    "ax.scatter(svclassifier.support_vectors_[:, 0], svclassifier.support_vectors_[:, 1],\n",
    "            s=100, linewidth=1, facecolors='none', edgecolors='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\r\n",
    "\r\n",
    "### The One-Class SVM\r\n",
    "\r\n",
    "- Imbalanced datasets are an intrinsic problem with many ML algorithms such as the SVM\r\n",
    "  - A significant imbalance between data classes makes ML model struggle to function\r\n",
    "  - The SVM has problems calculating the margin\r\n",
    "\r\n",
    "<img src=\"./images/oc-svm-margin.png\" alt=\"Margin\" style=\"width: 360px;\" />\r\n",
    "\r\n",
    "- One-Class SVM, or OC-SVM, solves this problem\r\n",
    "  - Uses only the majority class to designate the decision boundary\r\n",
    "  - Treats anything outside the boundary as an anomaly\r\n",
    "\r\n",
    "<img src=\"./images/oc-svm-classification.png\" alt=\"Classification\" style=\"width: 360px;\" />\r\n",
    "\r\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "# Generate new random dataset\n",
    "formatted_data = get_data(50000, 0.2, True)\n",
    "\n",
    "# Split dataset by label - the OC-SVM is trained with Benign data ONLY\n",
    "oc_benign = formatted_data[formatted_data.malware_label == 1]\n",
    "oc_malware = formatted_data[formatted_data.malware_label == -1]\n",
    "\n",
    "# Split dataset into test and training \n",
    "oc_b_train, oc_b_test = train_test_split(oc_benign, test_size=(test_percent / 100), random_state=rand_state)\n",
    "oc_b_train = oc_b_train.drop(label, axis=1)\n",
    "\n",
    "# Set nu and gamma hyperparameters (nu is expected percentage of malware in dataset)\n",
    "nu_value = (len(oc_malware) / len(oc_b_test))\n",
    "gamma_val = 0.1\n",
    "\n",
    "# Combine malware with test sample for analysis\n",
    "oc_test = oc_b_test.append(oc_malware)\n",
    "oc_test_label = oc_test.malware_label\n",
    "oc_test = oc_test.drop(label, axis=1)\n",
    "\n",
    "# Train/Fit OC-SVM data model\n",
    "svclassifier = OneClassSVM(nu=nu_value, kernel='rbf', gamma=gamma_val)\n",
    "svclassifier.fit(oc_b_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\r\n",
    "\r\n",
    "### OC-SVM Scores\r\n",
    "\r\n",
    "- Calculate how the OC-SVM performs (not speed, but correctness)\r\n",
    "- Scores used:\r\n",
    "  - Accuracy\r\n",
    "  - Precision\r\n",
    "  - Recall\r\n",
    "  - F2 Score\r\n",
    "\r\n",
    "<img src=\"./images/precision-recall-relevance.png\" alt=\"Precision-Recall\" style=\"width: 600px;\" />\r\n",
    "\r\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Calculate F-scores\n",
    "def f_beta(beta, precision, recall):\n",
    "    return (beta*beta + 1) * precision * recall / (beta * beta * precision + recall)\n",
    "\n",
    "# Perform n-fold cross validation and calculate the mean score across the cv=## folds\n",
    "print('\\nCalculating OC-SVM scores...')\n",
    "for val in ['accuracy', 'precision', 'recall']:\n",
    "    score = cross_val_score(svclassifier, oc_test, oc_test_label, cv=5, scoring=val).mean()\n",
    "    print(\"{}: {}\".format(val, score))\n",
    "    if val == 'precision':\n",
    "        prec = score\n",
    "    elif val == 'recall':\n",
    "        rec = score\n",
    "print(\"F2 Score: {}\".format(f_beta(2.0, prec, rec)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\r\n",
    "\r\n",
    "### OC-SVM Performance Graphs\r\n",
    "\r\n",
    "- Finally, visualize OC-SVM performance\r\n",
    "- Left graph is Confusion Matrix showing\r\n",
    "  - True-Positive\r\n",
    "  - True-Negative\r\n",
    "  - False-Positive\r\n",
    "  - False-Negative\r\n",
    "- Right graph is Reciver Operating Curve (ROC) graph\r\n",
    "  - Represents F1-score of model\r\n",
    "  - Everything \"inside\" or \"below\" the yellow line is correctly classified\r\n",
    "\r\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "oc_pred = svclassifier.predict(oc_test)\n",
    "ben = 0\n",
    "mal = 1\n",
    "oc_pred[oc_pred == 1] = 0\n",
    "oc_pred[oc_pred == -1] = 1\n",
    "\n",
    "oc_test_label[oc_test_label == 1] = 0\n",
    "oc_test_label[oc_test_label == -1] = 1\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, sharex=False, figsize=(15,8))\n",
    "\n",
    "# Generate AUC graph\n",
    "fpr, tpr, _ = roc_curve(oc_test_label, oc_pred)\n",
    "auc = roc_auc_score(oc_test_label, oc_pred)\n",
    "plt.plot([0,1], [0,1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.plot(fpr, tpr, label='ROC Curve (area = {})'.format(str(auc)), color='darkorange')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Receiver Operating Characteristic (ROC curve)')\n",
    "\n",
    "# Generate Confusion Matrix\n",
    "conf_matrix = confusion_matrix(oc_test_label, oc_pred)\n",
    "sns.heatmap(conf_matrix, ax=ax1,\n",
    "        xticklabels=['Benign', 'Malware'],\n",
    "        yticklabels=['Benign', 'Malware'],\n",
    "        annot=True, fmt='d')\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}